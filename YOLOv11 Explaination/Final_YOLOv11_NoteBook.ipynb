{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "1rhTT7WLZyD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RS56tUBJZtYV"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import random\n",
        "from time import time\n",
        "\n",
        "import math\n",
        "import numpy\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.nn.functional import cross_entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_seed():\n",
        "    \"\"\"\n",
        "    Setup random seed.\n",
        "    \"\"\"\n",
        "    random.seed(0)\n",
        "    numpy.random.seed(0)\n",
        "    torch.manual_seed(0)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n"
      ],
      "metadata": {
        "id": "847LkfY1Z1FN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wh2xy(x):\n",
        "    y = x.clone() if isinstance(x, torch.Tensor) else numpy.copy(x)\n",
        "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
        "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
        "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
        "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
        "    return y\n",
        "\n"
      ],
      "metadata": {
        "id": "o_brAnLrZ62g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_anchors(x, strides, offset=0.5):\n",
        "    assert x is not None\n",
        "    anchor_tensor, stride_tensor = [], []\n",
        "    dtype, device = x[0].dtype, x[0].device\n",
        "    for i, stride in enumerate(strides):\n",
        "        _, _, h, w = x[i].shape\n",
        "        sx = torch.arange(end=w, device=device, dtype=dtype) + offset  # shift x\n",
        "        sy = torch.arange(end=h, device=device, dtype=dtype) + offset  # shift y\n",
        "        sy, sx = torch.meshgrid(sy, sx)\n",
        "        anchor_tensor.append(torch.stack((sx, sy), -1).view(-1, 2))\n",
        "        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n",
        "    return torch.cat(anchor_tensor), torch.cat(stride_tensor)\n",
        "\n"
      ],
      "metadata": {
        "id": "N8hlmxIEZ8Y8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv11 Model Code\n"
      ],
      "metadata": {
        "id": "5yYLKUSlaHYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def fuse_conv(conv, norm):\n",
        "    fused_conv = torch.nn.Conv2d(conv.in_channels,\n",
        "                                 conv.out_channels,\n",
        "                                 kernel_size=conv.kernel_size,\n",
        "                                 stride=conv.stride,\n",
        "                                 padding=conv.padding,\n",
        "                                 groups=conv.groups,\n",
        "                                 bias=True).requires_grad_(False).to(conv.weight.device)\n",
        "\n",
        "    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
        "    w_norm = torch.diag(norm.weight.div(torch.sqrt(norm.eps + norm.running_var)))\n",
        "    fused_conv.weight.copy_(torch.mm(w_norm, w_conv).view(fused_conv.weight.size()))\n",
        "\n",
        "    b_conv = torch.zeros(conv.weight.size(0), device=conv.weight.device) if conv.bias is None else conv.bias\n",
        "    b_norm = norm.bias - norm.weight.mul(norm.running_mean).div(torch.sqrt(norm.running_var + norm.eps))\n",
        "    fused_conv.bias.copy_(torch.mm(w_norm, b_conv.reshape(-1, 1)).reshape(-1) + b_norm)\n",
        "\n",
        "    return fused_conv\n",
        "\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, activation, k=1, s=1, p=0, g=1):\n",
        "        super().__init__()\n",
        "        self.conv = torch.nn.Conv2d(in_ch, out_ch, k, s, p, groups=g, bias=False)\n",
        "        self.norm = torch.nn.BatchNorm2d(out_ch, eps=0.001, momentum=0.03)\n",
        "        self.relu = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.norm(self.conv(x)))\n",
        "\n",
        "    def fuse_forward(self, x):\n",
        "        return self.relu(self.conv(x))\n",
        "\n",
        "\n",
        "class Residual(torch.nn.Module):\n",
        "    def __init__(self, ch, e=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(ch, int(ch * e), torch.nn.SiLU(), k=3, p=1)\n",
        "        self.conv2 = Conv(int(ch * e), ch, torch.nn.SiLU(), k=3, p=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv2(self.conv1(x))\n",
        "\n",
        "\n",
        "class C3K(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(in_ch, out_ch // 2, torch.nn.SiLU())\n",
        "        self.conv2 = Conv(in_ch, out_ch // 2, torch.nn.SiLU())\n",
        "        self.conv3 = Conv(2 * (out_ch // 2), out_ch, torch.nn.SiLU())\n",
        "        self.res_m = torch.nn.Sequential(Residual(out_ch // 2, e=1.0),\n",
        "                                         Residual(out_ch // 2, e=1.0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.res_m(self.conv1(x))\n",
        "        return self.conv3(torch.cat((y, self.conv2(x)), dim=1))\n",
        "\n",
        "\n",
        "class C3K2(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, n, csp, r):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(in_ch, 2 * (out_ch // r), torch.nn.SiLU())\n",
        "        self.conv2 = Conv((2 + n) * (out_ch // r), out_ch, torch.nn.SiLU())\n",
        "\n",
        "        if not csp:\n",
        "            self.res_m = torch.nn.ModuleList(Residual(out_ch // r) for _ in range(n))\n",
        "        else:\n",
        "            self.res_m = torch.nn.ModuleList(C3K(out_ch // r, out_ch // r) for _ in range(n))\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = list(self.conv1(x).chunk(2, 1))\n",
        "        y.extend(m(y[-1]) for m in self.res_m)\n",
        "        return self.conv2(torch.cat(y, dim=1))\n",
        "\n",
        "\n",
        "class SPP(torch.nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, k=5):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(in_ch, in_ch // 2, torch.nn.SiLU())\n",
        "        self.conv2 = Conv(in_ch * 2, out_ch, torch.nn.SiLU())\n",
        "        self.res_m = torch.nn.MaxPool2d(k, stride=1, padding=k // 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        y1 = self.res_m(x)\n",
        "        y2 = self.res_m(y1)\n",
        "        return self.conv2(torch.cat(tensors=[x, y1, y2, self.res_m(y2)], dim=1))\n",
        "\n",
        "\n",
        "class Attention(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, ch, num_head):\n",
        "        super().__init__()\n",
        "        self.num_head = num_head\n",
        "        self.dim_head = ch // num_head\n",
        "        self.dim_key = self.dim_head // 2\n",
        "        self.scale = self.dim_key ** -0.5\n",
        "\n",
        "        self.qkv = Conv(ch, ch + self.dim_key * num_head * 2, torch.nn.Identity())\n",
        "\n",
        "        self.conv1 = Conv(ch, ch, torch.nn.Identity(), k=3, p=1, g=ch)\n",
        "        self.conv2 = Conv(ch, ch, torch.nn.Identity())\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(b, self.num_head, self.dim_key * 2 + self.dim_head, h * w)\n",
        "\n",
        "        q, k, v = qkv.split([self.dim_key, self.dim_key, self.dim_head], dim=2)\n",
        "\n",
        "        attn = (q.transpose(-2, -1) @ k) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (v @ attn.transpose(-2, -1)).view(b, c, h, w) + self.conv1(v.reshape(b, c, h, w))\n",
        "        return self.conv2(x)\n",
        "\n",
        "\n",
        "class PSABlock(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, ch, num_head):\n",
        "        super().__init__()\n",
        "        self.conv1 = Attention(ch, num_head)\n",
        "        self.conv2 = torch.nn.Sequential(Conv(ch, ch * 2, torch.nn.SiLU()),\n",
        "                                         Conv(ch * 2, ch, torch.nn.Identity()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.conv1(x)\n",
        "        return x + self.conv2(x)\n",
        "\n",
        "\n",
        "class PSA(torch.nn.Module):\n",
        "    def __init__(self, ch, n):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(ch, 2 * (ch // 2), torch.nn.SiLU())\n",
        "        self.conv2 = Conv(2 * (ch // 2), ch, torch.nn.SiLU())\n",
        "        self.res_m = torch.nn.Sequential(*(PSABlock(ch // 2, ch // 128) for _ in range(n)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, y = self.conv1(x).chunk(2, 1)\n",
        "        return self.conv2(torch.cat(tensors=(x, self.res_m(y)), dim=1))\n",
        "\n",
        "\n",
        "class DarkNet(torch.nn.Module):\n",
        "    def __init__(self, width, depth, csp):\n",
        "        super().__init__()\n",
        "        self.p1 = []\n",
        "        self.p2 = []\n",
        "        self.p3 = []\n",
        "        self.p4 = []\n",
        "        self.p5 = []\n",
        "\n",
        "        # p1/2\n",
        "        self.p1.append(Conv(width[0], width[1], torch.nn.SiLU(), k=3, s=2, p=1))\n",
        "        # p2/4\n",
        "        self.p2.append(Conv(width[1], width[2], torch.nn.SiLU(), k=3, s=2, p=1))\n",
        "        self.p2.append(C3K2(width[2], width[3], depth[0], csp[0], r=4))\n",
        "        # p3/8\n",
        "        self.p3.append(Conv(width[3], width[3], torch.nn.SiLU(), k=3, s=2, p=1))\n",
        "        self.p3.append(C3K2(width[3], width[4], depth[1], csp[0], r=4))\n",
        "        # p4/16\n",
        "        self.p4.append(Conv(width[4], width[4], torch.nn.SiLU(), k=3, s=2, p=1))\n",
        "        self.p4.append(C3K2(width[4], width[4], depth[2], csp[1], r=2))\n",
        "        # p5/32\n",
        "        self.p5.append(Conv(width[4], width[5], torch.nn.SiLU(), k=3, s=2, p=1))\n",
        "        self.p5.append(C3K2(width[5], width[5], depth[3], csp[1], r=2))\n",
        "        self.p5.append(SPP(width[5], width[5]))\n",
        "        self.p5.append(PSA(width[5], depth[4]))\n",
        "\n",
        "        self.p1 = torch.nn.Sequential(*self.p1)\n",
        "        self.p2 = torch.nn.Sequential(*self.p2)\n",
        "        self.p3 = torch.nn.Sequential(*self.p3)\n",
        "        self.p4 = torch.nn.Sequential(*self.p4)\n",
        "        self.p5 = torch.nn.Sequential(*self.p5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        p1 = self.p1(x)\n",
        "        p2 = self.p2(p1)\n",
        "        p3 = self.p3(p2)\n",
        "        p4 = self.p4(p3)\n",
        "        p5 = self.p5(p4)\n",
        "        return p3, p4, p5\n",
        "\n",
        "\n",
        "class DarkFPN(torch.nn.Module):\n",
        "    def __init__(self, width, depth, csp):\n",
        "        super().__init__()\n",
        "        self.up = torch.nn.Upsample(scale_factor=2)\n",
        "        self.h1 = C3K2(width[4] + width[5], width[4], depth[5], csp[0], r=2)\n",
        "        self.h2 = C3K2(width[4] + width[4], width[3], depth[5], csp[0], r=2)\n",
        "        self.h3 = Conv(width[3], width[3], torch.nn.SiLU(), k=3, s=2, p=1)\n",
        "        self.h4 = C3K2(width[3] + width[4], width[4], depth[5], csp[0], r=2)\n",
        "        self.h5 = Conv(width[4], width[4], torch.nn.SiLU(), k=3, s=2, p=1)\n",
        "        self.h6 = C3K2(width[4] + width[5], width[5], depth[5], csp[1], r=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        p3, p4, p5 = x\n",
        "        p4 = self.h1(torch.cat(tensors=[self.up(p5), p4], dim=1))\n",
        "        p3 = self.h2(torch.cat(tensors=[self.up(p4), p3], dim=1))\n",
        "        p4 = self.h4(torch.cat(tensors=[self.h3(p3), p4], dim=1))\n",
        "        p5 = self.h6(torch.cat(tensors=[self.h5(p4), p5], dim=1))\n",
        "        return p3, p4, p5\n",
        "\n",
        "\n",
        "class DFL(torch.nn.Module):\n",
        "    # Generalized Focal Loss\n",
        "    # https://ieeexplore.ieee.org/document/9792391\n",
        "    def __init__(self, ch=16):\n",
        "        super().__init__()\n",
        "        self.ch = ch\n",
        "        self.conv = torch.nn.Conv2d(ch, out_channels=1, kernel_size=1, bias=False).requires_grad_(False)\n",
        "        x = torch.arange(ch, dtype=torch.float).view(1, ch, 1, 1)\n",
        "        self.conv.weight.data[:] = torch.nn.Parameter(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, a = x.shape\n",
        "        x = x.view(b, 4, self.ch, a).transpose(2, 1)\n",
        "        return self.conv(x.softmax(1)).view(b, 4, a)\n",
        "\n",
        "\n",
        "class Head(torch.nn.Module):\n",
        "    anchors = torch.empty(0)\n",
        "    strides = torch.empty(0)\n",
        "\n",
        "    def __init__(self, nc=80, filters=()):\n",
        "        super().__init__()\n",
        "        self.ch = 16  # DFL channels\n",
        "        self.nc = nc  # number of classes\n",
        "        self.nl = len(filters)  # number of detection layers\n",
        "        self.no = nc + self.ch * 4  # number of outputs per anchor\n",
        "        self.stride = torch.zeros(self.nl)  # strides computed during build\n",
        "\n",
        "        box = max(64, filters[0] // 4)\n",
        "        cls = max(80, filters[0], self.nc)\n",
        "\n",
        "        self.dfl = DFL(self.ch)\n",
        "        self.box = torch.nn.ModuleList(torch.nn.Sequential(Conv(x, box,torch.nn.SiLU(), k=3, p=1),\n",
        "                                                           Conv(box, box,torch.nn.SiLU(), k=3, p=1),\n",
        "                                                           torch.nn.Conv2d(box, out_channels=4 * self.ch,\n",
        "                                                                           kernel_size=1)) for x in filters)\n",
        "        self.cls = torch.nn.ModuleList(torch.nn.Sequential(Conv(x, x, torch.nn.SiLU(), k=3, p=1, g=x),\n",
        "                                                           Conv(x, cls, torch.nn.SiLU()),\n",
        "                                                           Conv(cls, cls, torch.nn.SiLU(), k=3, p=1, g=cls),\n",
        "                                                           Conv(cls, cls, torch.nn.SiLU()),\n",
        "                                                           torch.nn.Conv2d(cls, out_channels=self.nc,\n",
        "                                                                           kernel_size=1)) for x in filters)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, (box, cls) in enumerate(zip(self.box, self.cls)):\n",
        "            x[i] = torch.cat(tensors=(box(x[i]), cls(x[i])), dim=1)\n",
        "        if self.training:\n",
        "            return x\n",
        "\n",
        "        self.anchors, self.strides = (i.transpose(0, 1) for i in make_anchors(x, self.stride))\n",
        "        x = torch.cat([i.view(x[0].shape[0], self.no, -1) for i in x], dim=2)\n",
        "        box, cls = x.split(split_size=(4 * self.ch, self.nc), dim=1)\n",
        "\n",
        "        a, b = self.dfl(box).chunk(2, 1)\n",
        "        a = self.anchors.unsqueeze(0) - a\n",
        "        b = self.anchors.unsqueeze(0) + b\n",
        "        box = torch.cat(tensors=((a + b) / 2, b - a), dim=1)\n",
        "\n",
        "        return torch.cat(tensors=(box * self.strides, cls.sigmoid()), dim=1)\n",
        "\n",
        "    def initialize_biases(self):\n",
        "        # Initialize biases\n",
        "        # WARNING: requires stride availability\n",
        "        for box, cls, s in zip(self.box, self.cls, self.stride):\n",
        "            # box\n",
        "            box[-1].bias.data[:] = 1.0\n",
        "            # cls (.01 objects, 80 classes, 640 image)\n",
        "            cls[-1].bias.data[:self.nc] = math.log(5 / self.nc / (640 / s) ** 2)\n",
        "\n",
        "\n",
        "class YOLO(torch.nn.Module):\n",
        "    def __init__(self, width, depth, csp, num_classes):\n",
        "        super().__init__()\n",
        "        self.net = DarkNet(width, depth, csp)\n",
        "        self.fpn = DarkFPN(width, depth, csp)\n",
        "\n",
        "        img_dummy = torch.zeros(1, width[0], 256, 256)\n",
        "        self.head = Head(num_classes, (width[3], width[4], width[5]))\n",
        "        self.head.stride = torch.tensor([256 / x.shape[-2] for x in self.forward(img_dummy)])\n",
        "        self.stride = self.head.stride\n",
        "        self.head.initialize_biases()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = self.fpn(x)\n",
        "        return self.head(list(x))\n",
        "\n",
        "    def fuse(self):\n",
        "        for m in self.modules():\n",
        "            if type(m) is Conv and hasattr(m, 'norm'):\n",
        "                m.conv = fuse_conv(m.conv, m.norm)\n",
        "                m.forward = m.fuse_forward\n",
        "                delattr(m, 'norm')\n",
        "        return self\n",
        "\n",
        "\n",
        "def yolo_v11_n(num_classes: int = 80):\n",
        "    csp = [False, True]\n",
        "    depth = [1, 1, 1, 1, 1, 1]\n",
        "    width = [3, 16, 32, 64, 128, 256]\n",
        "    return YOLO(width, depth, csp, num_classes)\n",
        "\n",
        "\n",
        "def yolo_v11_t(num_classes: int = 80):\n",
        "    csp = [False, True]\n",
        "    depth = [1, 1, 1, 1, 1, 1]\n",
        "    width = [3, 24, 48, 96, 192, 384]\n",
        "    return YOLO(width, depth, csp, num_classes)\n",
        "\n",
        "\n",
        "def yolo_v11_s(num_classes: int = 80):\n",
        "    csp = [False, True]\n",
        "    depth = [1, 1, 1, 1, 1, 1]\n",
        "    width = [3, 32, 64, 128, 256, 512]\n",
        "    return YOLO(width, depth, csp, num_classes)\n",
        "\n",
        "\n",
        "def yolo_v11_m(num_classes: int = 80):\n",
        "    csp = [True, True]\n",
        "    depth = [1, 1, 1, 1, 1, 1]\n",
        "    width = [3, 64, 128, 256, 512, 512]\n",
        "    return YOLO(width, depth, csp, num_classes)\n",
        "\n",
        "\n",
        "def yolo_v11_l(num_classes: int = 80):\n",
        "    csp = [True, True]\n",
        "    depth = [2, 2, 2, 2, 2, 2]\n",
        "    width = [3, 64, 128, 256, 512, 512]\n",
        "    return YOLO(width, depth, csp, num_classes)\n",
        "\n",
        "\n",
        "def yolo_v11_x(num_classes: int = 80):\n",
        "    csp = [True, True]\n",
        "    depth = [2, 2, 2, 2, 2, 2]\n",
        "    width = [3, 96, 192, 384, 768, 768]\n",
        "    return YOLO(width, depth, csp, num_classes)"
      ],
      "metadata": {
        "id": "apJbp9yfaB-3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Model"
      ],
      "metadata": {
        "id": "g32iAdJKJOdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo -q\n",
        "from torchinfo import summary\n",
        "summary(yolo_v11_n(), input_data=torch.randn(1,3,640,640))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kefL54B5nh6-",
        "outputId": "3ca94571-4152-4b42-d5af-fd38f590ffe5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                                            Output Shape              Param #\n",
              "===================================================================================================================\n",
              "YOLO                                                              [1, 84, 8400]             --\n",
              "├─DarkNet: 1-1                                                    [1, 128, 80, 80]          --\n",
              "│    └─Sequential: 2-1                                            [1, 16, 320, 320]         --\n",
              "│    │    └─Conv: 3-1                                             [1, 16, 320, 320]         464\n",
              "│    └─Sequential: 2-2                                            [1, 64, 160, 160]         --\n",
              "│    │    └─Conv: 3-2                                             [1, 32, 160, 160]         4,672\n",
              "│    │    └─C3K2: 3-3                                             [1, 64, 160, 160]         6,640\n",
              "│    └─Sequential: 2-3                                            [1, 128, 80, 80]          --\n",
              "│    │    └─Conv: 3-4                                             [1, 64, 80, 80]           36,992\n",
              "│    │    └─C3K2: 3-5                                             [1, 128, 80, 80]          26,080\n",
              "│    └─Sequential: 2-4                                            [1, 128, 40, 40]          --\n",
              "│    │    └─Conv: 3-6                                             [1, 128, 40, 40]          147,712\n",
              "│    │    └─C3K2: 3-7                                             [1, 128, 40, 40]          87,040\n",
              "│    └─Sequential: 2-5                                            [1, 256, 20, 20]          --\n",
              "│    │    └─Conv: 3-8                                             [1, 256, 20, 20]          295,424\n",
              "│    │    └─C3K2: 3-9                                             [1, 256, 20, 20]          346,112\n",
              "│    │    └─SPP: 3-10                                             [1, 256, 20, 20]          164,608\n",
              "│    │    └─PSA: 3-11                                             [1, 256, 20, 20]          249,728\n",
              "├─DarkFPN: 1-2                                                    [1, 64, 80, 80]           --\n",
              "│    └─Upsample: 2-6                                              [1, 256, 40, 40]          --\n",
              "│    └─C3K2: 2-7                                                  [1, 128, 40, 40]          --\n",
              "│    │    └─Conv: 3-12                                            [1, 128, 40, 40]          49,408\n",
              "│    │    └─ModuleList: 3-13                                      --                        37,056\n",
              "│    │    └─Conv: 3-14                                            [1, 128, 40, 40]          24,832\n",
              "│    └─Upsample: 2-8                                              [1, 128, 80, 80]          --\n",
              "│    └─C3K2: 2-9                                                  [1, 64, 80, 80]           --\n",
              "│    │    └─Conv: 3-15                                            [1, 64, 80, 80]           16,512\n",
              "│    │    └─ModuleList: 3-16                                      --                        9,312\n",
              "│    │    └─Conv: 3-17                                            [1, 64, 80, 80]           6,272\n",
              "│    └─Conv: 2-10                                                 [1, 64, 40, 40]           --\n",
              "│    │    └─Conv2d: 3-18                                          [1, 64, 40, 40]           36,864\n",
              "│    │    └─BatchNorm2d: 3-19                                     [1, 64, 40, 40]           128\n",
              "│    │    └─SiLU: 3-20                                            [1, 64, 40, 40]           --\n",
              "│    └─C3K2: 2-11                                                 [1, 128, 40, 40]          --\n",
              "│    │    └─Conv: 3-21                                            [1, 128, 40, 40]          24,832\n",
              "│    │    └─ModuleList: 3-22                                      --                        37,056\n",
              "│    │    └─Conv: 3-23                                            [1, 128, 40, 40]          24,832\n",
              "│    └─Conv: 2-12                                                 [1, 128, 20, 20]          --\n",
              "│    │    └─Conv2d: 3-24                                          [1, 128, 20, 20]          147,456\n",
              "│    │    └─BatchNorm2d: 3-25                                     [1, 128, 20, 20]          256\n",
              "│    │    └─SiLU: 3-26                                            [1, 128, 20, 20]          --\n",
              "│    └─C3K2: 2-13                                                 [1, 256, 20, 20]          --\n",
              "│    │    └─Conv: 3-27                                            [1, 256, 20, 20]          98,816\n",
              "│    │    └─ModuleList: 3-28                                      --                        181,248\n",
              "│    │    └─Conv: 3-29                                            [1, 256, 20, 20]          98,816\n",
              "├─Head: 1-3                                                       [1, 84, 8400]             --\n",
              "│    └─ModuleList: 2-18                                           --                        (recursive)\n",
              "│    │    └─Sequential: 3-30                                      [1, 64, 80, 80]           78,144\n",
              "│    └─ModuleList: 2-19                                           --                        (recursive)\n",
              "│    │    └─Sequential: 3-31                                      [1, 80, 80, 80]           19,904\n",
              "│    └─ModuleList: 2-18                                           --                        (recursive)\n",
              "│    │    └─Sequential: 3-32                                      [1, 64, 40, 40]           115,008\n",
              "│    └─ModuleList: 2-19                                           --                        (recursive)\n",
              "│    │    └─Sequential: 3-33                                      [1, 80, 40, 40]           25,728\n",
              "│    └─ModuleList: 2-18                                           --                        (recursive)\n",
              "│    │    └─Sequential: 3-34                                      [1, 64, 20, 20]           188,736\n",
              "│    └─ModuleList: 2-19                                           --                        (recursive)\n",
              "│    │    └─Sequential: 3-35                                      [1, 80, 20, 20]           37,376\n",
              "│    └─DFL: 2-20                                                  [1, 4, 8400]              --\n",
              "│    │    └─Conv2d: 3-36                                          [1, 1, 4, 8400]           (16)\n",
              "===================================================================================================================\n",
              "Total params: 2,624,080\n",
              "Trainable params: 2,624,064\n",
              "Non-trainable params: 16\n",
              "Total mult-adds (Units.GIGABYTES): 3.24\n",
              "===================================================================================================================\n",
              "Input size (MB): 4.92\n",
              "Forward/backward pass size (MB): 271.58\n",
              "Params size (MB): 10.50\n",
              "Estimated Total Size (MB): 286.99\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}